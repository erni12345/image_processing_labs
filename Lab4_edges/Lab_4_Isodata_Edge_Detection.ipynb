{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "source": [
    "<div style=\"display: none\">\n",
    "    <h1> . </h1>\n",
    "    <h1> . </h1>\n",
    "    <h1> . </h1>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing Python Lab - ISODATA & EDGE DETECTION\n",
    "\n",
    "\n",
    "Here is a guide to the different symbols of the lab: <br>\n",
    "\n",
    "<span style=\"font-size: 20px\">‚ùì</span> - This symbol means that there is a required theoretical question related to the assignment. Your answer to the specified question should go in the yellow box below it. <br>\n",
    "\n",
    "<span style=\"font-size: 20px\">‚ÑπÔ∏è</span> - This symbol means that there is some additional or important information related to the lab or specific exercise. <br>\n",
    "\n",
    "<span style=\"font-size: 20px\">üí¨</span> - This symbol means that the following text is part of the overarching story you follow, giving you more context into what you are doing and how it is applicable in real life situations.\n",
    "<hr style=\"height:1px; border:none; background-color:#00A6D6;\">\n",
    "\n",
    "__Objectives__\n",
    "- Implement the Canny algorithm\n",
    "- Implement the ISODATA thresholding algorithm\n",
    "- Implement the Adaptive thresholding algorithm\n",
    "\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to PDF\n",
    "\n",
    "<div style=\"background-color:#0DA006; padding:10px; color: white; border-radius: 10px\" >\n",
    "First try to convert to PDF via LaTeX:\n",
    "<ul>\n",
    "  <li>First you need to make sure that you have LaTeX installed (this goes for whatever operating system you are using). You can go to https://www.latex-project.org/get/ and get the proper distribution for your operating system.</li>\n",
    "  <li>After doing that, you can go to where xelatex.exe is found (this should be in AppData\\Local\\Programs\\MiKTeX\\miktex\\bin\\x64\\xelatex.exe if you are getting MiKTeXfor Windows, or the equivalent on other any other OS). If you are having a hard time finding the folder, you can use \"where xelatex\" as a command for Windows, the find command for Mac and Linux or just use the file explorer.</li>\n",
    "  <li>After making sure you have xelatex setup, you can try the \"PDF via LaTeX\" in the \"File\" -> \"Download as\" menu in jupyter notebook</li>\n",
    "</ul>\n",
    "If the above option does not work you can follow these instructions:\n",
    "<ul>\n",
    "  <li>Go into \"File\" -> \"Print Preview\"</li>\n",
    "  <li>Make sure the generated PDF is readable then you can use Ctrl+P or Command+P (on MacOS) to Print Page, where you select to save to PDF rather than printing (each system has a different interface).</li>\n",
    "  <li><b>Before submitting make sure that all answers/code/plots are clearly visible.<b></li>\n",
    "</ul>\n",
    "If none of the methods work, contact a TA during labs and ask about further steps.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#00A6D6; padding:10px; color: white; border-radius: 10px\" >\n",
    "<p style=\"font-size:25px\">üí¨</p>\n",
    "A new day at the office. As usual, you went to grab your cup of coffee when you saw your colleague Jeeves on his desk. You went to check on him and see how it is going. And as usual, he is quite busy with one of his regular tasks of manually cropping plates from images so that they are post processed for different running investigations. He asks you if you managed to create a system that can automatically or at least semi-automatically do the cropping for him. That would save him tons of hours.You promised to look into it and see what you can do to help!\n",
    "You went to your desk, thinking about how can you use your skills as an expert in image processing to solve his problem when you remembered, EDGE DETECTION techniques.  You turn on your laptop and start experimenting. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib for data visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import NumPy for better matrix support\n",
    "import numpy as np\n",
    "\n",
    "# import Pickle for data serialisation\n",
    "import pickle as pkl\n",
    "\n",
    "# import cv2 and imutils for image processing functionality\n",
    "import cv2\n",
    "import imutils\n",
    "\n",
    "# import scipy for convolutions\n",
    "from scipy import signal\n",
    "\n",
    "# import time for timing methods\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PYTHON HANDS-ON Assignment IV.1:  Canny algorithm\n",
    "\n",
    "The first exercise consists of the Canny algorithm, here you will implement the entire algorithm from scratch. Down below you can find a Canny crash course. <b> But before going into that, please watch this video about the idea behind Canny edge detection, https://youtu.be/sRFM5IEqR2w </b> . \n",
    " \n",
    "\n",
    "#### Canny Crash Course\n",
    "\n",
    "The Canny algorithm has the purpose of highlighting the edges of objects in an image. To achieve this, there are 5 steps you need to take, to fully implement the Canny algorithm. Steps are:\n",
    "1. Smooth the image with an appropriate filter\n",
    "2. Find the gradient and direction of the image\n",
    "3. Surpress non maximal values\n",
    "4. Apply thresholds to find weak and strong edges\n",
    "5. Run through the found edges and decide which to keep (Edge running)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<b> Overall pipeline of Canny </b>\n",
    "\n",
    "In the following image you will be able to see the Canny algorithm pipeline step by step, on an image with just the license plate.\n",
    "\n",
    "<img src='resources/lab_05/other/canny_pipeline.png' alt='Canny algorithm pipeline'>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Completion requirements for this assignment:**\n",
    "- [ ] Implement all steps of the Canny algorithm\n",
    "- [ ] Enhance resulting binary image using morphology\n",
    "- [ ] Answer all theory questions\n",
    "\n",
    "\n",
    "<div style=\"background-color:#c2eafa\"> \n",
    "    \n",
    "### IV.1.1 Get the gradient and directions of an image\n",
    "    \n",
    "Implement the missing parts of the code template marked with `#TODO`. If you feel like this code template does not meet your needs, feel free to change it. The function below should return the gradient and direction of the gradient. Use the Sobel kernel to compute the gradients.\n",
    "    \n",
    "‚ÑπÔ∏è Throughout this question you might want to plot the intermediate results. We advise to use the [plt.imshow()](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html) function, but make sure you read through its parameters so your image is displayed correctly. As a starter, always set the vmin and vmax according to what you're plotting, otherwise it will take the minimal and maximal value of your image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradient(image):\n",
    "    # Sobel gradient in x and y direction\n",
    "    Sobel_kernel_y = np.zeros((3, 3))\n",
    "    #TODO fill in the correct values for the Sobel gradient in Y direction\n",
    "\n",
    "    Sobel_kernel_x = np.zeros((3, 3))\n",
    "    #TODO fill in the correct values for the Sobel gradient in X direction\n",
    "    \n",
    "    \n",
    "    image2 = np.float64(image)\n",
    "    image3 = np.float64(image)\n",
    "    I_x = cv2.filter2D(image2, -1, Sobel_kernel_x)\n",
    "    I_y = cv2.filter2D(image3, -1, Sobel_kernel_y)\n",
    "    \n",
    "    # Gradient magnitude\n",
    "    #TODO compute the \"g\" gradient magnitude function.\n",
    "    g = 0\n",
    "    \n",
    "    # Gradient orientation\n",
    "    #TODO compute the \"theta\" gradient orientation function.\n",
    "    #Don't remove the code line below otherwise you will get division by zero errors\n",
    "    I_x[I_x == 0] = 0.0001\n",
    "    theta = 0\n",
    "    \n",
    "    \n",
    "    return g, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Non-max suppression (Edge Thinning) </b>\n",
    "\n",
    "Now that we have the direction and the gradient, we need to filter out values that are not important for us to find edges. We do this using Non-max suppression. Non Maximum Suppression (NMS) is a technique used in numerous computer vision tasks. It is a class of algorithms to select one entity (e.g., edges,  bounding boxes) out of many overlapping entities. We can choose the selection criteria to arrive at the desired results. The criteria are most commonly some form of probability number and some form of overlap measure (e.g. Intersection over Union) [ https://learnopencv.com/non-maximum-suppression-theory-and-implementation-in-pytorch/ ]. The idea behind non-max suppression is that we only keep the values that are the maximum in any direction compared to their 8 neighbours. To do this we need to check the direction of the pixel we are checking, and decide into which half of a quadrant does it fall into. Based on that we can than check values in that direction and find whether the pixel value is dominant in its direction (whether it is within epsilon of the maximal value of that direction).\n",
    "    \n",
    "<div style=\"background-color:#c2eafa\"> \n",
    "\n",
    "### IV.1.2 Non-Maximum suppression    \n",
    "\n",
    "Implement the non-maximum suppression using the help of the pseudo-code of the non-max suppression given:\n",
    "\n",
    "<img src='resources/lab_04/other/non_max_surpression.png' alt='Non max supression pseudocode'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_max_supression(gradient, direction, epsilon=0.000001):\n",
    "    # Create empty matrix of image shape\n",
    "    \n",
    "    # Loop over every pixel\n",
    "    \n",
    "            # Check the direction of the pixel\n",
    "        \n",
    "            # Based on direction find whether the value is to be saved or not\n",
    "            \n",
    "    # Return matrix with only max values\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    \n",
    " Now that we have selected specific values of interest from the gradient, we need to decide what is an edge and what is not an edge. We do this by thresholding the values we have, with input thresholds. There are 2 inputs, lower threshold and upper threshold, everything larger than the upper threshold is considered a **strong** edge, while everything in between the lower and upper threshold is considered a **weak** edge. Everything below the lower threshold is not considered at all. This is also the point where we start binarizing our image, such that it will be easy to extract edges in the end. This step can be formalized into the following formula:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Image_{thresh}(x, y)= \n",
    "\\begin{cases}\n",
    "    strong,& \\text{if } threshold_{upper} \\leq Image_{surpressed}(x, y)\\\\\n",
    "    weak,& \\text{if } threshold_{lower} < Image_{surpressed}(x, y) < threshold_{upper}\\\\\n",
    "    0,              & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "<div style=\"background-color:#c2eafa\"> \n",
    "\n",
    "### IV.1.3 Apply thresholds\n",
    "    \n",
    "Implement the function below that applied the Canny thresholds as explained in the section above. You can use `cv2.threshold` function to apply the thresholds. You can also experiment with `np.where()`, both of these methods would yield faster implementations, but within the scope of the lab, efficiency is not the main goal.\n",
    "    \n",
    " <span style=\"font-size: 20px\">‚ÑπÔ∏è</span> Detailed documentation to the `cv2.threshold` function can be found here https://docs.opencv.org/4.x/d7/d4d/tutorial_py_thresholding.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The weak and strong arguments are numbers we use to mark whether a pixel contains a weak or a strong edge\n",
    "def apply_thresholds(edges_supressed, lower, upper, weak=127, strong=255):\n",
    "    # Create an empty result array with same shape as edges\n",
    "    result = None\n",
    "    \n",
    "    # Loop over the found edges\n",
    "\n",
    "            # If edge value is >= than the upper limit, label it as strong\n",
    "\n",
    "            # If edge value is within (lower, upper), label it as weak\n",
    "            \n",
    "            # Otherwise, label it as 0\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    "    \n",
    "<b> Edge running </b>\n",
    "\n",
    "We now already have some edges, however we still have **weak** edges to decide whether they are an edge or not. This is done through a process called edge running, where we iterate over all **weak** edges and decide whether they are indeed an edge, by checking whether other **strong** edges can be found within its neighbours.\n",
    "\n",
    "\n",
    "<div style=\"background-color:#c2eafa\"> \n",
    "\n",
    "### IV.1.4 Edge running\n",
    " \n",
    "Implement the edge running function to deal with the weak edges. If your implementation takes too much time, you can only loop over the weak edges, rather than looping over all edges (for example with `np.where()`).\n",
    "\n",
    "<span style=\"font-size: 20px\">‚ÑπÔ∏è</span> You can use a similar implementation to the 3x3 median filter, but instead of using the median value, you are cheking for the max value in a neighborhood.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The weak and strong arguments are numbers we use to mark whether a pixel contains a weak or a strong edge\n",
    "def edge_running(edges, weak=127, strong=255):\n",
    "    # Create an empty result array with same shape as edges\n",
    "    result = None\n",
    "    \n",
    "    # Loop over edges\n",
    "\n",
    "            # If the edges is weak, check if there is a maximal value withing its closest neighbours\n",
    "\n",
    "            # If there is a maximum, mark it as a strong edge, if not then discard the edge\n",
    "\n",
    "            # If the edge is already strong, mark it as strong\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\"> \n",
    "\n",
    "### IV.1.5 Putting it together\n",
    "In this exercise the code is already there, however you still need to try to define the ideal variables. First try to use static variables (pre-defined as a number) and then try to assign them dynamically (mainly the `lower` and `upper` thresholds, try to assign them based on the image)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny(image, size, sigma, lower, upper):\n",
    "    # Making the image greyscale\n",
    "    image_grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Noise reduction using Gaussian kernel - step 1 of Canny\n",
    "    kernel = cv2.getGaussianKernel(size, sigma)\n",
    "    image_f = cv2.filter2D(image_grey, -1, kernel)\n",
    "    \n",
    "    # Gradient calculation - step 2 of Canny\n",
    "    gradient, direction = get_gradient(image_f)\n",
    "\n",
    "    # Non-maximum suppression - step 3 of Canny\n",
    "    gradient_thin = non_max_supression(gradient, direction)\n",
    "\n",
    "    # Double threshold - step 4 of Canny\n",
    "    edges = apply_thresholds(gradient_thin, lower, upper)\n",
    "    \n",
    "    # Edge running\n",
    "    result = edge_running(edges)\n",
    "    return np.uint8(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Variables (Choose the ones you find best fitting)\n",
    "sigma = 0\n",
    "size = 0\n",
    "lower = 0\n",
    "upper = 0\n",
    "\n",
    "path = 'lab_04/exercise01/'\n",
    "\n",
    "# Test\n",
    "input_image = cv2.imread(path + 'car.png')\n",
    "edges = canny(input_image, size, sigma, lower, upper)\n",
    "\n",
    "plt.imshow(edges, cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\"> \n",
    "\n",
    "### IV.1.6 Enhance using morhology\n",
    "You can see that even the Canny algorithm is not perfect, and there are still many holes in the edges. However, we already know the techniques to fix this. Use morphology techniques you used in week 2 to enhance the edge image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance(image):\n",
    "    # Create a morhology pipeline that improves quality of edges\n",
    "     \n",
    "    return None\n",
    "\n",
    "plt.imshow(enhance(edges), cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\"> \n",
    "\n",
    "<span style=\"font-size: 20px\">‚ùì</span>\n",
    "<i>\n",
    "What are the factors that are needed to be considered in choosing the low & high thresholds in the Canny edge detection technique?\n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e; padding:10px; color: white; border-radius: 10px\" >\n",
    "\n",
    "**Type your answer here.**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\"> \n",
    "\n",
    "<span style=\"font-size: 20px\">‚ùì</span>\n",
    "<i>\n",
    "How would you define the low & high threshold values to dynamically work on any edge image? \n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e; padding:10px; color: white; border-radius: 10px\" >\n",
    "\n",
    "**Type your answer here.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\"> \n",
    "\n",
    "<span style=\"font-size: 20px\">‚ùì</span>\n",
    "<i>\n",
    "What do you think about the following: Would using sharpening in addition to morphology enhance the continuity of the detected edges? (Hint: It is optional to try it in the code. )</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e; padding:10px; color: white; border-radius: 10px\" >\n",
    "\n",
    "**Type your answer here.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\"> \n",
    "\n",
    "<span style=\"font-size: 20px\">‚ùì</span>\n",
    "<i>\n",
    "Can you think of more ways to enhance the edges even more ? Explain.\n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e; padding:10px; color: white; border-radius: 10px\" >\n",
    "\n",
    "**Type your answer here.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PYTHON HANDS-ON Assignment IV.2: ISODATA thresholding\n",
    "\n",
    "<div style=\"background-color:#00A6D6; padding:10px; color: white; border-radius: 10px\" >\n",
    "<p style=\"font-size:25px\">üí¨</p>\n",
    "It is that day of the year! Everyone is dressed so elegantly  because it is photoday. Every year on the 10th of December everyone in the precinct takes a group photo. This photo is used to send Christmas cards to each employee in the office.\n",
    "As usual, they came to you to help  in applying special effects to the image. This year they want to have a black and white image instead of a colored one to have this vintage effect.  \n",
    "</div>\n",
    "\n",
    "\n",
    "**Completion requirements for this assignment:**\n",
    "- [ ] Implement ISODATA thresholding\n",
    "- [ ] Answer all theory questions\n",
    "\n",
    "<div style=\"background-color:#c2eafa\"> \n",
    "\n",
    "### V.2.1 Implement ISODATA thresholding\n",
    "Complete the following Isodata thresholding code by finalizing code where `#TODO`. Of course, if you feel like the given code template does not suit your needs, you are free to change it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'lab_04/exercise02/'\n",
    "\n",
    "def isodata_thresholding(image, epsilon = 2):\n",
    "    # Compute the histogram and set up variables\n",
    "    hist = np.array(cv2.calcHist([image], [0], None, [256], [0, 256])).flatten()\n",
    "    tau = np.random.randint(hist.nonzero()[0][0], 256 - hist[::-1].nonzero()[0][0])\n",
    "    old_tau = -2*epsilon\n",
    "    \n",
    "    # Iterations of the isodata thresholding algorithm\n",
    "    while(abs(tau - old_tau) >= epsilon):\n",
    "        #TODO Calculate m1\n",
    "        m1 = None\n",
    "        #TODO Calculate m2\n",
    "        m2 = None\n",
    "        \n",
    "        #TODO Calculate new tau\n",
    "        old_tau = tau\n",
    "        tau = None\n",
    "    \n",
    "    #TODO Threshold the image based on last tau\n",
    "    background = None\n",
    "    foreground = None\n",
    "    return background, foreground, tau\n",
    "\n",
    "image = cv2.imread(path + 'students.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "epsilon = 0.1\n",
    "\n",
    "background, foreground, tau = isodata_thresholding(image, epsilon)\n",
    "\n",
    "hist = np.array(cv2.calcHist([image], [0], None, [256], [0, 256])).flatten()\n",
    "plt.axvline(x=tau, color='red')\n",
    "plt.plot(hist)\n",
    "plt.title('Histogram of the image')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(background, cmap='gray', vmin=0, vmax=255)\n",
    "plt.title('background')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(foreground, cmap='gray', vmin=0, vmax=255)\n",
    "plt.title('foreground')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\"> \n",
    "\n",
    "<span style=\"font-size: 20px\">‚ùì</span>\n",
    "<i>\n",
    "Can you make the choice dynamic based on any input image data? Explain.\n",
    "\n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e; padding:10px; color: white; border-radius: 10px\" >\n",
    "\n",
    "**Type your answer here.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\"> \n",
    "\n",
    "<span style=\"font-size: 20px\">‚ùì</span>\n",
    "<i>\n",
    "Did you manage to perfectly binarize all the people in the image? Explain why?.\n",
    "\n",
    "\n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e; padding:10px; color: white; border-radius: 10px\" >\n",
    "\n",
    "**Type your answer here.**    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\"> \n",
    "\n",
    "<span style=\"font-size: 20px\">‚ùì</span>\n",
    "<i>\n",
    "How does ISODATA relate to the k-means clustering?\n",
    "\n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e; padding:10px; color: white; border-radius: 10px\" >\n",
    "\n",
    "**Type your answer here.**    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PYTHON HANDS-ON Assignment IV.3: Adaptive thresholding\n",
    "\n",
    "\n",
    "\n",
    "#### Adaptive thresholding crash course\n",
    "\n",
    "Adaptive thresholding is a different algorithm that solves the same problem as ISODATA thresholding, which is converting the image from grayscale to binary. Instead of having one global threshold for deciding if the pixel belongs to foreground or background as in ISODATA, adaptive thresholding decides the thresholds locally within a window of a specific size. The algorithm takes in 3 inputs, the image, the size (k) of the neighbourhood we should consider for the mean, and C, which serves as a constant of how far from the mean can the pixel value be to still be in higher interval. To formalize this, we can use the following formula:\n",
    "$$\n",
    "\\begin{equation}\n",
    "Foreground(x, y)= \n",
    "\\begin{cases}\n",
    "    255,& \\text{if } Image(x, y) \\geq \\text{mean}({Image(x - k : x + k, y - k : y + k)}) - C\\\\\n",
    "    0,              & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "Background(x, y)= \n",
    "\\begin{cases}\n",
    "    255,& \\text{if } Image(x, y) < \\text{mean}({Image(x - k : x + k, y - k : y + k)}) - C\\\\\n",
    "    0,              & \\text{otherwise}\n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "**Completion requirements for this assignment:**\n",
    "- [ ] Implement the adaptive thresholding algorithm\n",
    "- [ ] Answer all theory questions\n",
    "\n",
    "<div style=\"background-color:#c2eafa\"> \n",
    "\n",
    "### IV.3.1 Implement Adaptive thresholding\n",
    "Implement the missing parts of the code template marked with `#TODO`. After that, try at least 3 different combinations of parameters `size` & `c` to get the best required binarization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_thresholding(image, size, c):\n",
    "    # Create empty lower/ background and upper/foreground matrices\n",
    "    background = np.zeros(image.shape)\n",
    "    foreground = np.zeros(image.shape)\n",
    "    # Iterate over every pixxel in the image\n",
    "    for x in range(len(image)):\n",
    "        for y in range(len(image[x])):\n",
    "            #TODO Compute the mean of the window (window of shape [2*size + 1, 2*size + 1])\n",
    "            mean = None\n",
    "            \n",
    "            #TODO Decide whether an image falls into the foreground or background\n",
    "            \n",
    "    return background, foreground\n",
    "\n",
    "image = cv2.imread(path + 'students.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "background, foreground = adaptive_thresholding(image, 25, 15)\n",
    "plt.imshow(background, cmap='gray', vmin=0, vmax=255)\n",
    "plt.title('background')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(foreground, cmap='gray', vmin=0, vmax=255)\n",
    "plt.title('foreground')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\"> \n",
    "<span style=\"font-size: 20px\">‚ùì</span>\n",
    "<i>\n",
    "How does the size and C parameters influence the result of the algorithm ?\n",
    "\n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e; padding:10px; color: white; border-radius: 10px\" >\n",
    "\n",
    "**Type your answer here.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\"> \n",
    "<span style=\"font-size: 20px\">‚ùì</span>\n",
    "<i>\n",
    "What is the difference between using ISODATA vs. Adaptive thresholding?\n",
    "\n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e; padding:10px; color: white; border-radius: 10px\" >\n",
    "\n",
    "**Type your answer here.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#c2eafa\"> \n",
    "<span style=\"font-size: 20px\">‚ùì</span>\n",
    "<i>\n",
    "When would you use each & why? Provide an example when it is better to use ISODATA than Adaptive and vice versa.\n",
    "\n",
    "</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#f1be3e; padding:10px; color: white; border-radius: 10px\" >\n",
    "\n",
    "**Type your answer here.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è__**Checklist before submitting**__\n",
    "\n",
    "(try to fix anything that you can't tick from the checkboxes below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c42476c5c2246cfa4cf5c0e04a24241",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Filled in all of the yellow fields with answers to the questions marked wit‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db070daf44fc4d74bb1ee0b49b59ea8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description=\"Haven't used imports outside of those provided in the original notebook for‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb6a4d98eb24685a60957eaadd4bff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='All the code blocks can be run in sequence and execute successfully', inden‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1245d028854695a8f2d45dfd4af648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description=\"Haven't changed the layout or formatting in the notebook and have only writ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "\n",
    "check1 = widgets.Checkbox(              \n",
    "    value=False,\n",
    "    description='Filled in all of the yellow fields with answers to the questions marked with ‚ùì',\n",
    "    indent=False,\n",
    "    layout={'width':'1000px'}\n",
    ")\n",
    "check2 = widgets.Checkbox(              \n",
    "    value=False,\n",
    "    description='Haven\\'t used imports outside of those provided in the original notebook for this assignment',\n",
    "    indent=False,\n",
    "    layout={'width':'1000px'}\n",
    ")\n",
    "check3 = widgets.Checkbox(              \n",
    "    value=False,\n",
    "    description='All the code blocks can be run in sequence and execute successfully',\n",
    "    indent=False,\n",
    "    layout={'width':'1000px'}\n",
    ")\n",
    "check4 = widgets.Checkbox(              \n",
    "    value=False,\n",
    "    description='Haven\\'t changed the layout or formatting in the notebook and have only written in the appropriate code cells or yellow areas',\n",
    "    indent=False,\n",
    "    layout={'width':'1000px'}\n",
    ")\n",
    "display(check1, check2, check3, check4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "323px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
